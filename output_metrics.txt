
--- Logistic Regression (Optimized) ---
Acurácia: 0.8605
F1 Macro: 0.3945
Relatório de Classificação:
              precision    recall  f1-score   support

           0       0.87      0.99      0.93       331
           1       0.00      0.00      0.00        31
           2       0.67      0.16      0.26        25

    accuracy                           0.86       387
   macro avg       0.51      0.38      0.39       387
weighted avg       0.78      0.86      0.81       387

========================================

--- Random Forest (Optimized) ---
Acurácia: 0.7364
F1 Macro: 0.4264
Relatório de Classificação:
              precision    recall  f1-score   support

           0       0.88      0.81      0.85       331
           1       0.18      0.13      0.15        31
           2       0.20      0.48      0.28        25

    accuracy                           0.74       387
   macro avg       0.42      0.47      0.43       387
weighted avg       0.78      0.74      0.75       387

========================================

--- XGBoost (Optimized) ---
Acurácia: 0.8579
F1 Macro: 0.3532
Relatório de Classificação:
              precision    recall  f1-score   support

           0       0.86      1.00      0.92       331
           1       1.00      0.03      0.06        31
           2       0.50      0.04      0.07        25

    accuracy                           0.86       387
   macro avg       0.79      0.36      0.35       387
weighted avg       0.85      0.86      0.80       387

========================================

--- Neural Network (LSTM) ---
Acurácia: 0.8553
F1 Macro: 0.3073
Relatório de Classificação:
              precision    recall  f1-score   support

           0       0.86      1.00      0.92       331
           1       0.00      0.00      0.00        31
           2       0.00      0.00      0.00        25

    accuracy                           0.86       387
   macro avg       0.29      0.33      0.31       387
weighted avg       0.73      0.86      0.79       387

========================================

--- Transformer (Attention) ---
Acurácia: 0.7571
F1 Macro: 0.3239
Relatório de Classificação:
              precision    recall  f1-score   support

           0       0.86      0.87      0.87       331
           1       0.00      0.00      0.00        31
           2       0.08      0.16      0.10        25

    accuracy                           0.76       387
   macro avg       0.31      0.34      0.32       387
weighted avg       0.74      0.76      0.75       387

========================================
